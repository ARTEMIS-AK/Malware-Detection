# -*- coding: utf-8 -*-
"""SEMProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cE1hAit116wJZAVFrkV47z6i0YS1mg0D

#Aim:
 ##  Built machine learning model to detect malware.

##  Apply different machine learning models

##  Find the best suitable model that gives high accuracy and prediction

# **1) Importing Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# **2) Exploring the malware dataset.**

1) **41,323** binaries (exe, dll) - legitimate: This indicates that there are 41,323 binary files in the dataset, and these files are considered "legitimate".in this context, typically means that these files are not malware or malicious software. Binary files like .exe and .dll are common in Windows operating systems and are often associated with software applications and system libraries.

2) **96,724** malware files from **[virusshare.com](https://virusshare.com/about)**: This part of the information suggests that there are 96,724 files in the dataset that are categorized as **"malware."** These files are known to be malicious or harmful software, and have been obtained from virusshare.com, which is a website that collects and shares samples of various types of malware for research and analysis purposes.

**Malware Dataset:**https://drive.google.com/drive/folders/1Wi-9Eskzw7JMv0a5RcfYoxdTQS3hZ4xL?usp=sharing



## Features

Name: The name of the binary file.

md5: The MD5 hash of the binary file. MD5 is a cryptographic hash function often used to verify the integrity of files.

Machine: The target machine type or architecture for which the binary is intended (e.g., x86, x64, ARM).

SizeOfOptionalHeader: The size of the optional header in the binary file's header.

Characteristics: Flags or characteristics of the binary.

MajorLinkerVersion: The major version number of the linker used to create the binary.

MinorLinkerVersion: The minor version number of the linker used to create the binary.

SizeOfCode: The size of the code section in the binary.

SizeOfInitializedData: The size of initialized data in the binary.

SizeOfUninitializedData: The size of uninitialized data in the binary.

AddressOfEntryPoint: The address of the entry point of the binary, where execution starts.

BaseOfCode: The base address of the code section.

BaseOfData: The base address of the data section.

ImageBase: The preferred base address for loading the binary into memory.

SectionAlignment: The alignment of sections in memory.

FileAlignment: The alignment of sections in the file.

MajorOperatingSystemVersion: The major version of the operating system the binary is designed for.

MinorOperatingSystemVersion: The minor version of the operating system the binary is designed for.

MajorImageVersion: The major version of the image.

MinorImageVersion: The minor version of the image.

MajorSubsystemVersion: The major version of the subsystem.

MinorSubsystemVersion: The minor version of the subsystem.

SizeOfImage: The size of the image in memory.

SizeOfHeaders: The size of the headers in the binary.

CheckSum: The checksum value of the binary.

Subsystem: The subsystem that the binary is designed to run on (e.g., Windows GUI, Console).

DllCharacteristics: Flags or characteristics specific to dynamic link libraries (DLLs).

SizeOfStackReserve: The size of the stack to be reserved for the binary.

SizeOfStackCommit: The size of the stack to be committed for the binary.

SizeOfHeapReserve: The size of the heap to be reserved for the binary.

SizeOfHeapCommit: The size of the heap to be committed for the binary.

LoaderFlags: Flags related to the binary's loader.

NumberOfRvaAndSizes: The number of data-directory entries in the optional header.

SectionsNb: The number of sections in the binary.

SectionsMeanEntropy: The mean entropy of sections.

SectionsMinEntropy: The minimum entropy of sections.

SectionsMaxEntropy: The maximum entropy of sections.

SectionsMeanRawsize: The mean raw size of sections.

SectionsMinRawsize: The minimum raw size of sections.

SectionMaxRawsize: The maximum raw size of sections.

SectionsMeanVirtualsize: The mean virtual size of sections.

SectionsMinVirtualsize: The minimum virtual size of sections.

SectionMaxVirtualsize: The maximum virtual size of sections.

ImportsNbDLL: The number of DLLs imported by the binary.

ImportsNb: The number of imports (functions) in the binary.

ImportsNbOrdinal: The number of imported functions using an ordinal (numeric) value.

ExportNb: The number of exports (functions) from the binary.

ResourcesNb: The number of resources in the binary.

ResourcesMeanEntropy: The mean entropy of resources.

ResourcesMinEntropy: The minimum entropy of resources.

ResourcesMaxEntropy: The maximum entropy of resources.

ResourcesMeanSize: The mean size of resources.

ResourcesMinSize: The minimum size of resources.

ResourcesMaxSize: The maximum size of resources.

LoadConfigurationSize: The size of the load configuration data in the binary.

VersionInformationSize: The size of version information data in the binary.

legitimate: A binary label indicating whether the file is legitimate or malicious.




"""

malData=pd.read_csv("/content/drive/MyDrive/Malware Dataset/MalwareData.csv", sep="|", error_bad_lines=False, low_memory =True )

malData.head()

null_values = malData.isnull()

# Sum the null values for each column
null_count = null_values.sum()

print(null_count)

malData.info()

malData.shape

data_types = malData.dtypes

print(data_types)

data=malData
binary_columns = [c for c in data.columns if data[c].nunique() == 2]
categorical_columns = [c for c in data.columns if data[c].dtype == 'category']
numerical_columns = [c for c in data.columns if (c not in categorical_columns) & (c not in binary_columns)]

print("Numerical_columns", len(numerical_columns), numerical_columns, "\n")
print("Binary_columns", len(binary_columns), binary_columns, "\n")
print("Categorical_columns", len(categorical_columns), categorical_columns, "\n")

variables = {
    'categorical_columns': len(categorical_columns),
    'binary_variables': len(binary_columns),
    'numerical_columns': len(numerical_columns)
}

# Pie chart data
labels = variables.keys()
sizes = variables.values()
colors = ['blue', 'red', 'green']
explode = (0.1, 0, 0)

# Create a pie chart
plt.figure(figsize=(4, 4))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
plt.axis('equal')

plt.title("Variable Types")

plt.show()

malData.describe()

"""# The above plots shows the distributions of values for the different variables.

# EDA( Now, lets see the various plotings we can use.)
"""

legit= malData[0:41323].drop(["legitimate"], axis=1)
mal= malData[41323::].drop(["legitimate"], axis=1)
print("The shape of the legit dataset is: %s samples, %s features"%(legit.shape[0],legit.shape[1]))
print("The shape of the mal dataset is: %s samples, % s features" %(mal.shape[0],mal.shape[1]))

fig = plt.figure()
ax = fig.add_axes([0,0,1,1])
ax.hist(malData['legitimate'],20)
plt.show()

"""This histogram shows the number of legitimate and malwares in the dataset."""

sns.distplot(malData['ResourcesMeanEntropy'])

"""The "ResourcesMeanEntropy" feature indicates the average complexity of resources in executable files, with higher values suggesting greater complexity. Analyzing this feature helps identify unique characteristics within malware, aiding in detection."""

sns.countplot(data=malData, x='legitimate')
plt.title('Distribution of Malware vs. Legitimate Samples')
plt.show()

correlation_matrix = malData.corr(numeric_only=True)
figure, axis = plt.subplots(figsize=(40,25))
axis = sns.heatmap(correlation_matrix,
                   annot = True,
                   linewidth = 1,
                   fmt = ".2f",
                   cmap="YlOrRd");
bottom, top = axis.get_ylim()
axis.set_ylim(bottom + 0.5, top - 0.5);

"""# So as you can see, my dataset features are more, the above correlation matrix is looking clumsy. so what we can do here is use selected features to visualize more precisly"""

relevant_features = malData[['SizeOfOptionalHeader', 'Characteristics', 'MajorLinkerVersion',  'SectionsNb',  'ImportsNbDLL', 'ImportsNb', 'ExportNb', 'ResourcesNb', 'ResourcesMeanEntropy', 'ResourcesMeanSize', 'VersionInformationSize'
]]

corr_matrix = relevant_features.corr()

plt.figure(figsize=(12, 10))

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')

plt.title('Correlation Heatmap')

plt.show()

"""## From the above Correlation matrix, we get to know that the correlation values are very low between variables, so that means features in dataset are not at all related."""

corr_matrix = malData.corr(numeric_only=True)

correlation_threshold = 0.60
high_correlation_cols = []
for i in range(len(corr_matrix.columns)):
    for j in range(i+1, len(corr_matrix.columns)):
        if abs(corr_matrix.iloc[i, j]) > correlation_threshold:
            high_correlation_cols.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))

print("Column pairs with correlation > 0.60:")
for pair in high_correlation_cols:
    print(pair)

plt.style.use('ggplot')
for column in malData.columns:
    plt.figure(figsize=(8, 6))
    plt.hist(malData[column], bins=20)
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)


    plt.show()

"""## The above histograms shows the distribution of values for the features

# Model Building
"""

y=malData['legitimate']
malData=malData.drop(['legitimate'],axis=1)

malData=malData.drop(['Name'],axis=1)
malData=malData.drop(['md5'],axis=1)
print(" The Name and md5 variables are removed successfully")

"""# Spliting the dataset into test and train

"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(malData,y, test_size=0.2, random_state=42)

X_train.shape

X_test.shape

"""# 1)Logistic Regression"""

from sklearn.linear_model import LogisticRegression

clf = LogisticRegression(random_state=0)

logModel=clf.fit(X_train, y_train)

# Accuracy on the train dataset

train_log= logModel.predict(X_train)

accuracy_score(y_train,train_log)

# Accuracy on the test dataset

pred=logModel.predict(X_test)

accuracy_score(y_test,pred)

f1_score(y_test, pred)

"""Here F1 score of 0, it typically means that our model's performance is poor in terms of both precision and recall.  A low F1 score indicates that our model is not effectively predicting both the positive and negative classes."""

from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay

y_pred = logModel.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['legitimate', 'malicious'])

# Use the cmap parameter in the plot method
disp.plot(cmap='Blues')

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

y_pred = logModel.predict(X_test)

# classification metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Classification report
classification_rep = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

print("Classification Report:")
print(classification_rep)

"""From the above confusion matrix

we have 19,250 True Negatives, which means our model correctly predicted 19,250 instances as the negative class.

We have 0 False Positives, indicating that our model didn't make any incorrect predictions by classifying negative samples as positive.

We have 8,360 False Negatives, meaning that our model incorrectly predicted 8,360 instances as the negative class when they are actually positive.

**We have 0 True Positives, which implies that our model didn't correctly predict any instances as the positive class.**

## so we can say that regression model is not fit for this dataset

# 2) Random Forest
"""

from sklearn.ensemble import RandomForestClassifier

from sklearn.datasets import make_classification

clf = RandomForestClassifier(max_depth=2, random_state=0)

randomModel=clf.fit(X_train, y_train)

"""## Random forest Evaluation on test data

"""

from sklearn.metrics import f1_score,accuracy_score,auc,confusion_matrix,ConfusionMatrixDisplay

#  Accuracy on the train dataset

train_pred=randomModel.predict(X_train)

accuracy_score(y_train,train_pred)

# Accuracy on the test dataset

prediction=randomModel.predict(X_test)

accuracy_score(y_test,prediction)

f1_score(y_test, prediction)

from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay

y_pred = randomModel.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['legitimate', 'malicious'])

# Use the cmap parameter in the plot method
disp.plot(cmap='Blues')

"""# Report"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

y_pred = randomModel.predict(X_test)

# classification metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# report
classification_rep = classification_report(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

print("Classification Report:")
print(classification_rep)

"""The above random forest model give high accuracy, around 98%, which is a good score.

Accuracy: 0.9838102136906918

Precision: 0.9794014297831092

Recall: 0.966866028708134

F1 Score: 0.9730933606212002

# **3)Linear regression**
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

#Linear Regression model
Linmodel = LinearRegression()
Linmodel.fit(X_train, y_train)

# Make predictions on the test data
y_pred = Linmodel.predict(X_test)

# Evaluate the model's performance
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared (R2) Score:", r2)

"""From the above Linear regression model,we can see

**Mean Squared Error (MSE):** The MSE value of approximately ***0.0814*** indicates the average squared difference between the actual and predicted values. Lower MSE values suggest a better fit of the model to the data.

**R-squared (R2) Score:** An R2 score of approximately ***0.6142*** represents the proportion of variance explained by the model. A higher R2 score indicates that the model accounts for a larger portion of the variance in the target variable

## **hence we can say Random Forest is better than Linear regression model and is better applicable for my dataset than logistic regression**
"""

import pandas
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import KFold
from sklearn import model_selection
import sklearn.model_selection

models = []
models.append(('LR', LogisticRegression ()))
models.append(('LDA', LinearDiscriminantAnalysis ()))
models.append (('KNN', KNeighborsClassifier ()))
models.append(('CART', DecisionTreeClassifier()))
models.append (('NB', GaussianNB ()))
scoring='accuracy'
results = []
names = []
for name, model in models:
    kfold = model_selection.KFold(n_splits=10)
    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append (cv_results)
    names.append (name)
    msg = "%s:%f (%f)" % (name, cv_results.mean(), cv_results.std())
    print (msg)

import matplotlib.pyplot as plt

# Model names and their corresponding accuracy scores
model_names = ["LR", "LDA", "KNN", "CART", "NB","RF"]
accuracy_scores = [0.701522, 0.965646, 0.986725, 0.991479, 0.701549,0.982831]

# Create a bar chart
plt.bar(model_names, accuracy_scores, capsize=5)
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Model Comparison - Accuracy")
plt.ylim(0.6, 1.0)
plt.show()

"""We have calculated the accuracy scores for different models like Logistic regression, LinearDiscriminantAnalysis, KNeighborsClassifier, Descision Tree, Gaussian NB and random forest.

from the above we can see that Descsion tree have highest accuracy than random forest.

 models, like decision trees or random forests, are more robust to outliers and can handle them effectively.

 Instead of outright removing outliers, using robust statistical techniques that are less sensitive to outliers can be a better approach.

Random Forest and Decision Trees models are often preferred over Logistic Regression due to their ability to capture complex nonlinear relationships, handle interactions between features, and be robust to outliers and irrelevant features. However, the choice of model depends on the specific characteristics of the dataset and modeling goals.
"""

